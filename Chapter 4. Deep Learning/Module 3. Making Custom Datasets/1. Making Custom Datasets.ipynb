{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Datasets\n",
    "\n",
    "So far, we have only used the MNIST dataset, which is easily accessible through torchvision. What do we do when we have our own data which we want to use with PyTorch?\n",
    "\n",
    "In this notebook, we will covert our own raw data into PyTorch datasets that can be processed by our PyTorch models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What should our dataset be able to do?\n",
    "### ` __getitem__ `\n",
    "Our dataset should be a set of many examples. We should be able to index it like `my_dataset[3]` to get the example at position 3. The `__getitem__` function defines how the dataset is indexed, it is a function which should return an example datapoint given the example index as an argument. \n",
    "\n",
    "`mydataset[2]` is equivalent to `my_dataset.__getitem__(2)`\n",
    "\n",
    "### `__len__`\n",
    "The `__len__` function must return the length of the dataset we are loading in.\n",
    "\n",
    "`len(mydataset)` is equivalent to `my_dataset.__len__()`\n",
    "\n",
    "### It should also inherit from `torch.utils.data.Dataset`\n",
    "This just makes sure that we implement everything that we need to so that our dataset will be compatible with other utilities from torch such as the `DataLoader`."
   ]
  },
  {
   "source": [
    "## Dataset 1: The Auto MPG Dataset\n",
    "\n",
    "This dataset contains 398 examples of cars with 7 numerical features and their corresponding miles per gallon (MPG) as a label."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "398\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n0  18.0        8.0         307.0       130.0  3504.0          12.0   \n1  15.0        8.0         350.0       165.0  3693.0          11.5   \n2  18.0        8.0         318.0       150.0  3436.0          11.0   \n3  16.0        8.0         304.0       150.0  3433.0          12.0   \n4  17.0        8.0         302.0       140.0  3449.0          10.5   \n\n   model year  origin  \n0        70.0     1.0  \n1        70.0     1.0  \n2        70.0     1.0  \n3        70.0     1.0  \n4        70.0     1.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mpg</th>\n      <th>cylinders</th>\n      <th>displacement</th>\n      <th>horsepower</th>\n      <th>weight</th>\n      <th>acceleration</th>\n      <th>model year</th>\n      <th>origin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18.0</td>\n      <td>8.0</td>\n      <td>307.0</td>\n      <td>130.0</td>\n      <td>3504.0</td>\n      <td>12.0</td>\n      <td>70.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>15.0</td>\n      <td>8.0</td>\n      <td>350.0</td>\n      <td>165.0</td>\n      <td>3693.0</td>\n      <td>11.5</td>\n      <td>70.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>18.0</td>\n      <td>8.0</td>\n      <td>318.0</td>\n      <td>150.0</td>\n      <td>3436.0</td>\n      <td>11.0</td>\n      <td>70.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>16.0</td>\n      <td>8.0</td>\n      <td>304.0</td>\n      <td>150.0</td>\n      <td>3433.0</td>\n      <td>12.0</td>\n      <td>70.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17.0</td>\n      <td>8.0</td>\n      <td>302.0</td>\n      <td>140.0</td>\n      <td>3449.0</td>\n      <td>10.5</td>\n      <td>70.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "from utils import get_auto_mpg_data\n",
    "\n",
    "auto_mpg_data = get_auto_mpg_data()\n",
    "auto_mpg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoMPGDataset(Dataset):\n",
    "    def __init__(self):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class S40dataset(Dataset): # create dataset class\n",
    "\n",
    "    def __init__(self, img_dir='S40-data/images', annotation_dir='S40-data/annotations', transform=None):\n",
    "        self.img_dir = img_dir # what directory are the images in\n",
    "        self.annotation_dir = annotation_dir # what directory are the annotations in\n",
    "        self.transform = transform # what transforms were passed to the initialiser\n",
    "\n",
    "        self.img_names = os.listdir(img_dir) # list all files in the img folder\n",
    "        self.img_names.sort() # order the images alphabetically\n",
    "        self.img_names = [os.path.join(img_dir, img_name) for img_name in self.img_names] # join folder and file names\n",
    "\n",
    "        self.annotation_names = os.listdir(annotation_dir) # list all annotation files\n",
    "        self.annotation_names.sort() # order annotation files alphabetically\n",
    "        self.annotation_names = [os.path.join(annotation_dir, ann_name) for ann_name in self.annotation_names] # join folder and file names\n",
    "\n",
    "#         print(self.img_names)\n",
    "#         print(self.annotation_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_names[idx] # get the path of the image at that index\n",
    "        img = Image.open(img_name) # open the image using the path\n",
    "\n",
    "        annotation_name = self.annotation_names[idx] # get the path to the label file\n",
    "        annotation_tree = ET.parse(annotation_name) # use xml parser to load the file\n",
    "        bndbox_xml = annotation_tree.find(\"object\").find(\"bndbox\") # get the tag which contains our labels\n",
    "        \n",
    "        # get the x and y values for the corners of the rectangle\n",
    "        xmax = int(bndbox_xml.find('xmax').text) \n",
    "        ymax = int(bndbox_xml.find('ymax').text)\n",
    "        xmin = int(bndbox_xml.find('xmin').text)\n",
    "        ymin = int(bndbox_xml.find('ymin').text)\n",
    "        #print(xmax, ymax, xmin, ymin)\n",
    "\n",
    "        # Convert from corner co-ordinates format into center co-ordinate, width and height format\n",
    "        w = xmax - xmin #\n",
    "        h = ymax - ymin\n",
    "        x = int(xmin + w / 2)\n",
    "        y = int(ymin + h / 2)\n",
    "\n",
    "        # Normlise the labels so the values are expressed as a proportion of the whole image\n",
    "        x /= img.size[0]\n",
    "        w /= img.size[0]\n",
    "        y /= img.size[1]\n",
    "        h /= img.size[1]\n",
    "\n",
    "        bndbox = (x, y, w, h) # create tuple of bounding box dimensions\n",
    "        \n",
    "        if self.transform: # if any transforms were given to initialiser\n",
    "            img = self.transform(img) # apply any transforms\n",
    "\n",
    "        bndbox = torch.tensor(bndbox) # convert bounding box tuple to tensor\n",
    "\n",
    "        return img, bndbox\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "# Convert from  center co-ordinate, width and height format into corner co-ordinates format\n",
    "def unpack_bndbox(bndbox, img):\n",
    "#     bndbox = list(bndbox[0])\n",
    "    x, y, w, h = tuple(bndbox)\n",
    "    x *= img.size[0] \n",
    "    w *= img.size[0]\n",
    "    y *= img.size[1]\n",
    "    h *= img.size[1]\n",
    "    xmin = x - w / 2\n",
    "    xmax = x + w / 2\n",
    "    ymin = y - h / 2\n",
    "    ymax = y + h / 2\n",
    "    bndbox = [xmin, ymin, xmax, ymax]\n",
    "    return bndbox\n",
    "\n",
    "def show(batch, pred_bndbox=None):\n",
    "    img, bndbox = batch\n",
    "\n",
    "#     img = img[0]\n",
    "    print(img.shape)\n",
    "    img = transforms.ToPILImage()(img)\n",
    "    img = transforms.Resize((512, 512))(img)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    bndbox = unpack_bndbox(bndbox, img)\n",
    "    print(bndbox)\n",
    "    draw.rectangle(bndbox)\n",
    "    if pred_bndbox is not None:\n",
    "        pred_bndbox = unpack_bndbox(pred_bndbox, img)\n",
    "        draw.rectangle(pred_bndbox, outline=1000)\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'S40dataset' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-0ebaf53767c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmyS40\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mS40dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# initialise our dataset and transform each example with a ToTensor transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'len dataset:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyS40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# use our __len__ method to show the length of the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyS40\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# use our __getitem__ method to get the first example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'S40dataset' has no len()"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "myS40 = S40dataset(transform=transforms.ToTensor()) # initialise our dataset and transform each example with a ToTensor transform\n",
    "print('len dataset:', len(myS40)) # use our __len__ method to show the length of the dataset\n",
    "example = myS40[0] # use our __getitem__ method to get the first example\n",
    "show(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common way that we might then use this dataset would be to create a torch `DataLoader` from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "my_dataloader = # use dataset to create dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook complete\n",
    "\n",
    "You should now understand how to create your own dataset classes by inheriting from torch's `Dataset` class and overwriting the `__getitem__` and `__len__` methods.\n",
    "\n",
    "__Next Steps__\n",
    "\n",
    "- [CNN Detection](https://github.com/AI-Core/Convolutional-Neural-Networks/blob/master/CNN%20Detection.ipynb) - use this dataset to train a CNN to detect single instances in images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}